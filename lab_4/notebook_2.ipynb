{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xydrmfnDr7KX"
      },
      "source": [
        "### Установка пакетов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezujwGoDr-on",
        "outputId": "9043992a-f477-4b03-d58a-a30c0155c3f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3CMXpjpptKn"
      },
      "source": [
        "### Импорт библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0bxIuW3BnoW3"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "from pyspark.sql import SparkSession\n",
        "from sklearn.datasets import make_classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K0wrzBFOh6b"
      },
      "source": [
        "### Создание каталога data для хранения данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k6mJK8UWOgEZ"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('data'):\n",
        "  os.makedirs('data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29kEYlPZp64Z"
      },
      "source": [
        "### Создание экземпляра SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IGshgYlPsS5r"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName('Homework_3_lab2').getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Кластеризация (KMeans)"
      ],
      "metadata": {
        "id": "F_vuNOz0odR3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-SD5MFn07MT"
      },
      "source": [
        "### Задание 1. Сгенерировать подходящие исходные данные для проведения обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1. Определение функции генерации данных"
      ],
      "metadata": {
        "id": "RA7lRjAGq0N2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_file(path, X, y):\n",
        "  lines = []\n",
        "\n",
        "  for i in range(len(y)):\n",
        "    features = []\n",
        "\n",
        "    for j in range(len(X[0])):\n",
        "      features.append(f\"{j+1}:{X[i][j]}\")\n",
        "\n",
        "    lines.append(f\"{y[i]} {' '.join(features)}\")\n",
        "\n",
        "  with open(path, \"w\") as file:\n",
        "    file.write('\\n'.join(lines))"
      ],
      "metadata": {
        "id": "I42QdeTmqytZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2. Генерация данных"
      ],
      "metadata": {
        "id": "eQbWA_taq9NH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_classification(\n",
        "  n_samples=1000,\n",
        "  n_features=15,\n",
        "  n_informative=12,\n",
        "  n_redundant=3,\n",
        "  n_clusters_per_class=2,\n",
        "  n_classes=5\n",
        ")\n",
        "\n",
        "to_file('data/clusterization_data', X, y)"
      ],
      "metadata": {
        "id": "pWiSAG0PoqOI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3. Чтение данных из файла"
      ],
      "metadata": {
        "id": "plz46mW2rDwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format('libsvm').load('data/clusterization_data')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNvJFs0HrOoe",
        "outputId": "89f5723d-5900-49f8-8f33-b4edd5d514d9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(label=0.0, features=SparseVector(15, {0: -0.0548, 1: -1.8421, 2: -0.3111, 3: -1.8563, 4: 1.7194, 5: 1.7487, 6: 0.4585, 7: 1.9063, 8: -3.0565, 9: 2.1487, 10: 2.1825, 11: -2.7551, 12: -2.1576, 13: -5.6815, 14: -4.1576}))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 2. Провести кластеризацию с помощью pyspark.ml / pyspark.mllib"
      ],
      "metadata": {
        "id": "kM7XjFEP2FdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans().setK(5)\n",
        "model = kmeans.fit(df)"
      ],
      "metadata": {
        "id": "gxTOhSzn22Hb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(df)\n",
        "predictions.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB3cpfyo2_gE",
        "outputId": "be13cd9d-59d5-4439-d4c7-cbb4e0636a46"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(label=0.0, features=SparseVector(15, {0: -0.0548, 1: -1.8421, 2: -0.3111, 3: -1.8563, 4: 1.7194, 5: 1.7487, 6: 0.4585, 7: 1.9063, 8: -3.0565, 9: 2.1487, 10: 2.1825, 11: -2.7551, 12: -2.1576, 13: -5.6815, 14: -4.1576}), prediction=3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = ClusteringEvaluator().evaluate(predictions)\n",
        "evaluation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPlHhqj828sw",
        "outputId": "a97b7581-1f9b-4e91-bd08-e521eb2cd3cf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1834406800196666"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 3. Вывести и сохранить в файл полученные центры кластеров"
      ],
      "metadata": {
        "id": "zDeLp59s2NHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "centers = model.clusterCenters()\n",
        "centers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkVwWgrg24oI",
        "outputId": "2b9ede0d-40c8-4dc5-c4e5-f98aa9daa2f8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 2.07343973,  0.28063027,  0.53107784, -0.80946533, -0.84016241,\n",
              "         0.32100587, -0.34856495,  0.66882416,  0.53021513, -0.39921477,\n",
              "        -1.28909384,  0.86802634, -0.28573687,  2.9679894 ,  1.57510421]),\n",
              " array([-7.68185403, -1.16618   , -0.77265416,  0.79711368,  1.75812087,\n",
              "        -0.38748882, -0.27885783, -0.37499013,  1.7436419 ,  1.94492598,\n",
              "         1.04533645,  0.56350837, -1.62988183, -4.94600059,  2.90165429]),\n",
              " array([-4.30742384e+00, -3.09775330e-01,  2.29952237e-01, -2.78838445e-01,\n",
              "        -1.16793729e-01, -1.44100156e+00,  1.35002269e+00, -3.09411958e-01,\n",
              "         7.75087359e-01,  8.03381122e-02,  2.82554937e-01,  1.50576013e+00,\n",
              "        -2.00814419e-03,  1.75042644e+00,  8.50354363e-01]),\n",
              " array([ 0.4436992 , -0.08305864, -0.49697804, -0.445623  ,  0.52053708,\n",
              "         0.60800912, -0.44110774,  0.32071661, -0.32623804,  1.13344187,\n",
              "         0.43801357, -1.34384465, -0.32844806, -2.77488855, -0.99467163]),\n",
              " array([ 7.54008689,  1.13028103, -0.74450282, -1.74266094, -1.55468998,\n",
              "         0.74751928, -0.26039063,  0.66530953, -1.00888474, -0.76069279,\n",
              "        -0.59338611, -1.37926922,  1.49633374,  2.32472271, -3.11467036])]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('data/clusterization_data_r_2', 'w') as file:\n",
        "  for center in centers:\n",
        "    file.write(f'{center}\\n')"
      ],
      "metadata": {
        "id": "9EovFHEEAPRX"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}